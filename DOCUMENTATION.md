# IntakeAI â€” Patient Intake Assistant
### Comprehensive Project Documentation

---

## ðŸ“‹ Table of Contents

1. [Project Overview](#1-project-overview)
2. [Architecture](#2-architecture)
3. [Project Structure](#3-project-structure)
4. [Backend â€” File-by-File Reference](#4-backend--file-by-file-reference)
5. [Frontend â€” index.html](#5-frontend--indexhtml)
6. [AI Workflow (CrewAI Agents)](#6-ai-workflow-crewai-agents)
7. [API Reference](#7-api-reference)
8. [Setup & Installation](#8-setup--installation)
9. [Environment Variables](#9-environment-variables)
10. [Running the Application](#10-running-the-application)
11. [Known Issues & Troubleshooting](#11-known-issues--troubleshooting)
12. [Technology Stack](#12-technology-stack)

---

## 1. Project Overview

**IntakeAI** is an AI-powered patient intake assistant designed for healthcare settings. It collects patient information through a rich web interface â€” including typed text, voice recordings, medical documents, and symptom photos â€” and uses Google Gemini AI + CrewAI agents to automatically generate a structured, professional intake form ready for the doctor.

### Key Features
- ðŸŽ™ï¸ **Voice recording** â€” patients can speak their symptoms
- ðŸ“„ **Document upload** â€” prescriptions, lab reports, medical records (PDF/images)
- ðŸ“¸ **Symptom photo upload** â€” for visual conditions (wounds, rashes, etc.)
- ðŸ¤– **Multi-agent AI pipeline** â€” 4 specialized AI agents process and synthesize data
- ðŸ“‹ **Structured intake form** â€” generated in Markdown, rendered in the browser
- ðŸ–¨ï¸ **PDF export** â€” via browser print dialog
- ðŸ”’ **HIPAA-compliant design** â€” secure data handling

---

## 2. Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        BROWSER (User)                        â”‚
â”‚                  http://localhost:8080                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Screen 1    â”‚  â”‚    Screen 2       â”‚  â”‚   Screen 3    â”‚  â”‚
â”‚  â”‚  Input Form  â”‚â†’ â”‚   Processing      â”‚â†’ â”‚    Result     â”‚  â”‚
â”‚  â”‚  (Page 2)    â”‚  â”‚   (Page 1)        â”‚  â”‚   (Page 3)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ POST /intake (multipart/form-data)
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Backend (main.py)                   â”‚
â”‚                     Port: 8080                               â”‚
â”‚                                                              â”‚
â”‚  1. Transcribe audio  â†’  multimodal_tools.transcribe_audio() â”‚
â”‚  2. Analyze documents â†’  multimodal_tools.analyze_document() â”‚
â”‚  3. Analyze images    â†’  multimodal_tools.analyze_symptom()  â”‚
â”‚  4. Run CrewAI        â†’  4 agents, 4 tasks                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Google Gemini AI (via two SDKs)                 â”‚
â”‚                                                              â”‚
â”‚  â€¢ google-genai SDK   â†’ multimodal (audio, images, docs)    â”‚
â”‚  â€¢ langchain-google-genai â†’ CrewAI agent LLM calls          â”‚
â”‚                                                              â”‚
â”‚  Model: gemini-2.0-flash-lite                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Project Structure

```
files/
â”œâ”€â”€ main.py                # FastAPI app â€” API routes, orchestration
â”œâ”€â”€ agents.py              # CrewAI agent definitions (4 agents)
â”œâ”€â”€ tasks.py               # CrewAI task definitions (4 tasks)
â”œâ”€â”€ multimodal_tools.py    # Gemini multimodal functions (audio, images)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment variables (GOOGLE_API_KEY)
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html         # Single-page frontend (all 3 screens)
â”œâ”€â”€ temp_uploads/          # Temporary storage for uploaded files
â”œâ”€â”€ App.jsx                # (Legacy React component â€” not used)
â”œâ”€â”€ App.css                # (Legacy React styles â€” not used)
â””â”€â”€ package.json           # (Legacy React config â€” not used)
```

> **Note:** `App.jsx`, `App.css`, and `package.json` are legacy files from an earlier React-based frontend. The current frontend is `static/index.html`.

---

## 4. Backend â€” File-by-File Reference

### `main.py` â€” FastAPI Application

The main entry point. Handles:
- Serving the frontend (`GET /`)
- Receiving form submissions (`POST /intake`)
- Orchestrating the full AI pipeline

**Key Routes:**

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/` | Serves `static/index.html` |
| `POST` | `/intake` | Processes patient intake form |

**`POST /intake` â€” Request Parameters:**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `audio` | File (webm) | Optional | Patient voice recording |
| `text_input` | String | Optional | Typed symptom description |
| `documents` | File[] | Optional | Medical documents (PDF/images) |
| `symptom_images` | File[] | Optional | Photos of symptoms |

**`POST /intake` â€” Response:**

```json
{
  "intake_form": "# Patient Intake Form\n...(Markdown)...",
  "voice_transcription": "Patient said: ...",
  "documents_analyzed": 2,
  "symptom_images_analyzed": 1
}
```

**Processing Pipeline in `main.py`:**
1. Save uploaded audio â†’ transcribe â†’ delete temp file
2. Save uploaded documents â†’ analyze each â†’ delete temp files
3. Save uploaded symptom images â†’ analyze each â†’ delete temp files
4. Combine all text â†’ run CrewAI workflow â†’ return result

---

### `agents.py` â€” CrewAI Agents

Defines 4 specialized AI agents, each powered by `gemini-2.0-flash-lite` via `langchain-google-genai`.

| Agent | Role | Responsibility |
|-------|------|----------------|
| `intake_agent` | Patient Intake Specialist | Extracts demographics, chief complaint, symptoms |
| `history_agent` | Medical History Analyst | Extracts past conditions, medications, allergies |
| `document_agent` | Medical Document Analyst | Reads and interprets uploaded documents |
| `summary_agent` | Patient Profile Summarizer | Synthesizes all data into final intake form |

**Model Configuration:**
```python
ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-lite",
    google_api_key=os.getenv("GOOGLE_API_KEY")
)
```

---

### `tasks.py` â€” CrewAI Tasks

Defines 4 tasks that map to the 4 agents:

| Task | Agent | Input | Output |
|------|-------|-------|--------|
| `extract_basic_info` | intake_agent | voice/text | Demographics + chief complaint JSON |
| `analyze_documents` | document_agent | document analyses | Extracted medical data |
| `extract_medical_history` | history_agent | voice/text + docs | Medical history summary |
| `generate_intake_form` | summary_agent | all 3 above tasks | Final Markdown intake form |

**Final Intake Form Sections (generated by `generate_intake_form`):**
1. Patient Demographics
2. Chief Complaint & Symptoms
3. Symptom Timeline
4. Medical History
5. Current Medications
6. Allergies
7. Family History
8. Lifestyle & Social History
9. Documents Reviewed
10. Flags & Urgent Notes
11. Doctor Briefing Summary

---

### `multimodal_tools.py` â€” Gemini Multimodal Functions

Uses the `google-genai` SDK directly for multimodal AI calls.

#### `transcribe_audio(audio_file_path)`
- Converts audio to MP3 (via `pydub`) if needed
- Sends audio bytes to Gemini with transcription prompt
- Returns transcribed text string

#### `analyze_document_image(image_path)`
- Supports: JPG, PNG, PDF, GIF, WebP
- Sends document bytes to Gemini
- Extracts: patient details, medications, diagnoses, lab results, doctor notes

#### `analyze_symptom_image(image_path)`
- Supports: JPG, PNG, GIF, WebP
- Sends image bytes to Gemini
- Describes: visible condition, location, size, color/texture, concerning features

#### `wait_for_active_file(file_name)`
- Helper: polls until an uploaded Gemini file is in `ACTIVE` state
- Retries up to 30 times with 1-second delay

---

### `requirements.txt` â€” Python Dependencies

```
fastapi              # Web framework
uvicorn              # ASGI server
python-multipart     # For file upload parsing
crewai               # Multi-agent AI framework
langchain-google-genai  # LangChain wrapper for Gemini (used by CrewAI)
google-generativeai  # Google AI SDK
pydub                # Audio conversion (webm â†’ mp3)
python-dotenv        # .env file loading
```

**Install all dependencies:**
```bash
pip install -r requirements.txt
```

---

## 5. Frontend â€” `index.html`

A Single Page Application (SPA) with 3 screens, built with:
- **Tailwind CSS** (via CDN) â€” utility-first styling
- **Google Fonts** â€” Inter + Playfair Display
- **Material Symbols** â€” icons
- **Marked.js** â€” Markdown rendering for the result

### Screen Flow

```
[Screen 1: Input Form] â†’ (submit) â†’ [Screen 2: Processing] â†’ (AI done) â†’ [Screen 3: Result]
                                                                              â†“
                                                                        [Start Over]
                                                                              â†“
                                                                    [Screen 1: Input Form]
```

### Screen 1 â€” Input Form
- **Reason for Visit** dropdown (12 options)
- **Describe in your own words** textarea
- **Severity slider** (1â€“10, hidden for checkups/follow-ups)
- **Voice Note** â€” record audio via microphone
- **Upload Documents** â€” PDF or images
- **Symptom Photos** â€” shown only for Skin Condition / Injury or Wound
- **Continue to Review** button â†’ triggers `submitIntake()`

### Screen 2 â€” Processing
- Animated pulse rings with brain/neurology icon
- 4 animated step indicators showing AI progress
- Steps animate in sequentially with checkmarks

### Screen 3 â€” Result
- Displays generated intake form as rendered Markdown
- Shows generation date
- **Download as PDF** button (browser print dialog)
- **Start Over** button (resets to Screen 1)

### Key JavaScript Functions

| Function | Description |
|----------|-------------|
| `showScreen(id)` | Switches between screens with fade animation |
| `submitIntake()` | Validates form, builds FormData, calls `POST /intake` |
| `startRecording()` | Starts microphone recording via MediaRecorder API |
| `stopRecording()` | Stops recording, creates audio blob |
| `clearRecording()` | Removes recorded audio |
| `handleDocuments(e)` | Handles document file selection |
| `handleSymptomImages(e)` | Handles symptom image selection |
| `handleSymptomChange()` | Shows/hides severity + photo sections based on symptom type |
| `animateSteps()` | Animates processing step indicators |
| `resetAll()` | Clears all data and returns to Screen 1 |
| `showError(msg)` | Shows error banner on Screen 1 |

---

## 6. AI Workflow (CrewAI Agents)

The CrewAI workflow runs sequentially when `POST /intake` is called:

```
Patient Input (text + audio + docs + images)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   intake_agent      â”‚  Task 1: Extract basic info
â”‚   (T1)              â”‚  â†’ Name, age, chief complaint, symptoms, severity
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   document_agent    â”‚  Task 2: Analyze documents
â”‚   (T2)              â”‚  â†’ Medications, lab results, diagnoses
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   history_agent     â”‚  Task 3: Extract medical history
â”‚   (T3)              â”‚  â†’ Past conditions, allergies, family history
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   summary_agent     â”‚  Task 4: Generate final intake form
â”‚   (T4)              â”‚  â†’ Complete Markdown document (11 sections)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
   Markdown intake form returned to frontend
```

---

## 7. API Reference

### `GET /`
Returns the frontend HTML page.

**Response:** `text/html` â€” `static/index.html`

---

### `POST /intake`
Processes patient intake data and returns AI-generated form.

**Request:** `multipart/form-data`

| Field | Type | Description |
|-------|------|-------------|
| `audio` | File | Voice recording (webm format from browser) |
| `text_input` | String | Combined symptom text (reason + severity + description) |
| `documents` | File[] | Medical documents (PDF, JPG, PNG) |
| `symptom_images` | File[] | Symptom photos (JPG, PNG) |

**Success Response (200):**
```json
{
  "intake_form": "# Patient Intake Form\n## 1. PATIENT DEMOGRAPHICS\n...",
  "voice_transcription": "Patient reported headache for 3 days...",
  "documents_analyzed": 1,
  "symptom_images_analyzed": 0
}
```

**Error Response (500):**
```json
{
  "error": "Error message here"
}
```

**Common Errors:**
- `429 RESOURCE_EXHAUSTED` â€” Gemini API quota exceeded
- `404 NOT_FOUND` â€” Model name not available for API version

---

## 8. Setup & Installation

### Prerequisites
- Python 3.10 or higher
- pip
- Google AI Studio API key ([aistudio.google.com](https://aistudio.google.com))
- FFmpeg (required by pydub for audio conversion)

### Step 1: Install FFmpeg
FFmpeg is required for audio conversion (webm â†’ mp3).

**Windows:**
```bash
# Download from https://ffmpeg.org/download.html
# Or via winget:
winget install ffmpeg
```

### Step 2: Install Python Dependencies
```bash
pip install -r requirements.txt
```

### Step 3: Configure API Key
Create a `.env` file in the project root:
```
GOOGLE_API_KEY=your_google_api_key_here
```

Get your API key from: [aistudio.google.com/apikey](https://aistudio.google.com/apikey)

### Step 4: Run the Server
```bash
python main.py
```

### Step 5: Open the App
Navigate to: [http://localhost:8080](http://localhost:8080)

---

## 9. Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `GOOGLE_API_KEY` | âœ… Yes | Google Gemini API key from AI Studio |

**`.env` file format:**
```
GOOGLE_API_KEY=AIzaSy...your_key_here
```

---

## 10. Running the Application

```bash
# Start the server
python main.py

# Server starts at:
# INFO: Uvicorn running on http://0.0.0.0:8080
```

**To stop the server:** Press `Ctrl + C` in the terminal.

**To restart after code changes:**
```bash
# Stop with Ctrl+C, then:
python main.py
```

---

## 11. Known Issues & Troubleshooting

### âŒ `429 RESOURCE_EXHAUSTED` â€” Quota Exceeded
**Cause:** Free tier Gemini API quota has been used up.

**Solutions:**
1. Wait until the next day (quotas reset daily)
2. Get a new API key from a different Google account
3. Enable billing on your Google Cloud project

### âŒ `404 NOT_FOUND` â€” Model Not Available
**Cause:** The specified model name is not available for the API version being used.

**Solution:** Use `gemini-2.0-flash-lite` (currently set in both `agents.py` and `multimodal_tools.py`).

### âŒ `ERR_CONNECTION_REFUSED` â€” Server Not Running
**Cause:** The FastAPI server is not running.

**Solution:**
```bash
python main.py
```

### âŒ Audio transcription fails
**Cause:** FFmpeg not installed (required by pydub).

**Solution:** Install FFmpeg and ensure it's in your system PATH.

### âŒ Microphone not working in browser
**Cause:** Browser requires HTTPS for microphone access (except on localhost).

**Solution:** Use `http://localhost:8080` (not the IP address).

---

## 12. Technology Stack

### Backend
| Technology | Version | Purpose |
|------------|---------|---------|
| Python | 3.10+ | Runtime |
| FastAPI | Latest | Web framework |
| Uvicorn | Latest | ASGI server |
| CrewAI | Latest | Multi-agent AI orchestration |
| LangChain Google GenAI | Latest | LLM interface for CrewAI agents |
| Google GenAI SDK | Latest | Direct Gemini API calls (multimodal) |
| Pydub | Latest | Audio format conversion |
| Python-dotenv | Latest | Environment variable management |

### Frontend
| Technology | Purpose |
|------------|---------|
| HTML5 | Structure |
| Tailwind CSS (CDN) | Styling |
| Vanilla JavaScript | Logic & API calls |
| Google Fonts (Inter, Playfair Display) | Typography |
| Material Symbols | Icons |
| Marked.js | Markdown rendering |
| MediaRecorder API | Voice recording |

### AI Models
| Model | SDK | Used For |
|-------|-----|---------|
| `gemini-2.0-flash-lite` | google-genai | Audio transcription, document analysis, image analysis |
| `gemini-2.0-flash-lite` | langchain-google-genai | CrewAI agent reasoning |

---

## ðŸ“Œ Quick Reference

```bash
# Install dependencies
pip install -r requirements.txt

# Set API key in .env
echo "GOOGLE_API_KEY=your_key" > .env

# Run the app
python main.py

# Open in browser
# http://localhost:8080
```

---

*Documentation generated for IntakeAI v1.0 â€” February 2026*
